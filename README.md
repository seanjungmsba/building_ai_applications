---
<!-- header: Agenda -->

## Agenda

1. Use Cases
2. High-Level Architecture
3. Tokenization
4. Attention Mechanisms
5. Position Embeddings
6. Project 1 - Sentiment Analysis with Transformer from Scratch via PyTorch
7. Popular Variants - BERT and RoBERTa
8. Project 2 - Text Summarization with BERT Models from HuggingFace
9. Knowledge Distillation
10. Popular Variants - DistilBERT
11. Increasing Context Windows - RoPE and Flash Attention
12. Fine-tuning
13. Efficient Fine-tuning with Low Rank Adaptation (LoRa)
14. Popular Variants - T5
14. Project 3 - Fine-tuning T5 for Named Entity Recognition (NER) with Autotrain
16. Generalized Pretrained Transformer (GPT)
17. Project 4 - Building GPT from Scratch with PyTorch and Lightning AI
18. Alignment - RLHF and DPO
19. Project 5 - Improving GPT Responses with DPO
20. Large Language Models (LLMs)
21. Popular Variants - Llama Architecture
22. Project 6 - Fine-tuning Llama 3.3 8B for Medical Question-Answering with LitGPT
23. Popular Variants - DeepSeek
24. Alignment Variant - GRPO
25. Project 7 - Conducting Local Inference with DeepSeek via Ollama 

<!-- header: Use Cases -->

<center>

## Use Cases

</center>

1. Machine Translation
    - Translating spoken / written languages.
    - Converting one programming language to another.

2. Question Answering
    - Answering questions based on a given context.

3. Text Generation
    - Generating text based on a given prompt.
    - Summarizing long texts.

4. Classification
    - Classifying text into categories.
    - Sentiment analysis.

5. Named Entity Recognition
    - Identifying and classifying entities in text.

---
